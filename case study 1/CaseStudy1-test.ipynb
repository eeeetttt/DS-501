{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 1 : Collecting Data from Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Sampling Twitter Data with Streaming API about a Certain Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select and include a case topic that you are interested in, for example, \"WPI\" or \"Lady Gaga\" or COVID-19.\n",
    "* Use Twitter Streaming API to sample a collection of tweets about this topic in real time. It would be recommended that the number of tweets should be larger than 1000, but smaller than 1 million.\n",
    "* Store the tweets you downloaded into a local file (txt file or json file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<twitter.api.Twitter object at 0x000001E9A720A490>\n",
      "1.1.2\n"
     ]
    }
   ],
   "source": [
    "import twitter\n",
    "\n",
    "def oauth_login():\n",
    "    # XXX: Go to http://twitter.com/apps/new to create an app and get values\n",
    "    # for these credentials that you'll need to provide in place of these\n",
    "    # empty string values that are defined as placeholders.\n",
    "    # See https://developer.twitter.com/en/docs/basics/authentication/overview/oauth\n",
    "    # for more information on Twitter's OAuth implementation.\n",
    "    \n",
    "    CONSUMER_KEY = 'OEBQxusAmLaJIP2o3WQTCNxBA'\n",
    "    CONSUMER_SECRET ='rA29WDveS9w50jF9Ke0edA8xuS2oTcehi2Bq6J11cHPwR4RpQE'\n",
    "    OAUTH_TOKEN = '1492269919924195329-KdGOMwMHOJZFKTRvm3ha0zysLcg9ev'\n",
    "    OAUTH_TOKEN_SECRET = 'LQJTZ8HNc5qWleTxhUZYfAy37VJmKH75L9h9OFI2cCRZ0'\n",
    "    \n",
    "    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                               CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    \n",
    "    twitter_api = twitter.Twitter(auth=auth)\n",
    "    return twitter_api\n",
    "\n",
    "# Sample usage\n",
    "twitter_api = oauth_login()    \n",
    "\n",
    "# Nothing to see by displaying twitter_api except that it's now a\n",
    "# defined variable\n",
    "\n",
    "print(twitter_api)\n",
    "import flask\n",
    "print(flask.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "def twitter_search(twitter_api, q, max_results=1000, **kw):\n",
    "\n",
    "    # See https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets\n",
    "    # and https://developer.twitter.com/en/docs/tweets/search/guides/standard-operators\n",
    "    # for details on advanced search criteria that may be useful for \n",
    "    # keyword arguments\n",
    "    \n",
    "    # See https://dev.twitter.com/docs/api/1.1/get/search/tweets    \n",
    "    search_results = twitter_api.search.tweets(q=q, count=100, **kw)\n",
    "    \n",
    "    statuses = search_results['statuses']\n",
    "    \n",
    "    # Iterate through batches of results by following the cursor until we\n",
    "    # reach the desired number of results, keeping in mind that OAuth users\n",
    "    # can \"only\" make 180 search queries per 15-minute interval. See\n",
    "    # https://developer.twitter.com/en/docs/basics/rate-limits\n",
    "    # for details. A reasonable number of results is ~1000, although\n",
    "    # that number of results may not exist for all queries.\n",
    "    \n",
    "    # Enforce a reasonable limit\n",
    "    max_results = min(1000, max_results)\n",
    "    \n",
    "    for _ in range(10): # 10*100 = 1000\n",
    "        try:\n",
    "            next_results = search_results['search_metadata']['next_results']\n",
    "        except KeyError as e: # No more results when next_results doesn't exist\n",
    "            break\n",
    "            \n",
    "        # Create a dictionary from next_results, which has the following form:\n",
    "        # ?max_id=313519052523986943&q=NCAA&include_entities=1\n",
    "        kwargs = dict([ kv.split('=') \n",
    "                        for kv in next_results[1:].split(\"&\") ])\n",
    "        \n",
    "        search_results = twitter_api.search.tweets(**kwargs)\n",
    "        statuses += search_results['statuses']\n",
    "        \n",
    "        if len(statuses) > max_results: \n",
    "            break\n",
    "            \n",
    "    return statuses\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "q = 'Beijing2022'\n",
    "results = twitter_search(twitter_api, q, max_results=1000)\n",
    "        \n",
    "# Show one sample search result by slicing the list...\n",
    "data = json.dumps(results, indent=1)\n",
    "\n",
    "file = open('extracted_tweets_beijing_2022_final.txt', 'w')\n",
    "file.write(data)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Analyzing Tweets and Tweet Entities with Frequency Analysis\n",
    "\n",
    "**1. Word Count:** \n",
    "* Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets. \n",
    "* Plot a table of the top 30 words with their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------+\n",
      "| Word                | Count |\n",
      "+---------------------+-------+\n",
      "| #Beijing2022        |   539 |\n",
      "| #ÁæΩÁîüÁµêÂº¶           |   181 |\n",
      "| #ClosingCeremony    |   145 |\n",
      "| de                  |   139 |\n",
      "| @Olympics:          |   134 |\n",
      "| #„Éï„Ç£„ÇÆ„É•„Ç¢„Çπ„Ç±„Éº„Éà |   122 |\n",
      "| üòç                  |   102 |\n",
      "| ü§©                  |   102 |\n",
      "| #Âåó‰∫¨2022           |   101 |\n",
      "| #EXO                |   100 |\n",
      "| #ÏóëÏÜå               |   100 |\n",
      "| wait                |    97 |\n",
      "| #YuzuruHanyu        |    96 |\n",
      "| Can't               |    96 |\n",
      "| tonight's           |    96 |\n",
      "| @weareoneEXO        |    95 |\n",
      "| rocked              |    95 |\n",
      "| PyeongChang2018     |    95 |\n",
      "| üé∂üé§                |    95 |\n",
      "| ceremony!           |    95 |\n",
      "| #Grow‚Ä¶              |    95 |\n",
      "| Olympic             |    76 |\n",
      "| ÈÅ∏Êâã                |    55 |\n",
      "| #TeamGB             |    51 |\n",
      "| „Ç®„Ç≠„Ç∑„Éì„Ç∑„Éß„É≥      |    50 |\n",
      "| #Âåó‰∫¨‰∫îËº™           |    48 |\n",
      "| #Âåó‰∫¨„Ç™„É™„É≥„Éî„ÉÉ„ÇØ   |    46 |\n",
      "| medal               |    46 |\n",
      "| #Olympics           |    45 |\n",
      "| la                  |    45 |\n",
      "+---------------------+-------+\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from prettytable import PrettyTable\n",
    "import nltk\n",
    "\n",
    "tweet_texts = [ tweet['text'] \n",
    "                 for tweet in results ]\n",
    "words = [ word \n",
    "          for tweet in tweet_texts \n",
    "              for word in tweet.split()\n",
    "                 if word not in ['RT', '&amp;', '|'] # filter out RT and ampersand\n",
    "        ]\n",
    "\n",
    "# Use the natural language toolkit to eliminate stop words\n",
    "\n",
    "# nltk.download('stopwords') # download stop words if you do not have it\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "non_stop_words = [w for w in words if w.lower() not in stop_words]\n",
    "\n",
    "# frequency of words\n",
    "count = Counter(non_stop_words).most_common()\n",
    "\n",
    "# table of the top 30 words with their counts\n",
    "pretty_table = PrettyTable(field_names=['Word', 'Count']) \n",
    "[ pretty_table.add_row(w) for w in count[:30] ]\n",
    "pretty_table.align['Word'] = 'l'\n",
    "pretty_table.align['Count'] = 'r'\n",
    "print(pretty_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Find the most popular tweets in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------------------------------------------------------------------------------+\n",
      "| Retweets | Text                                                                                        |\n",
      "+----------+---------------------------------------------------------------------------------------------+\n",
      "| 18641    | RT @Japan_Olympic: Ôºè                                                                       |\n",
      "|          | Ê±∫Âãù„ÅØÊòéÊó•ÔºÅ #„Ç´„Éº„É™„É≥„Ç∞ Â•≥Â≠êü•å                                                             |\n",
      "|          | ÈÅ∏Êâã„Åü„Å°„Åã„Çâ„É°„ÉÉ„Çª„Éº„Ç∏„ÅåÂ±ä„Åç„Åæ„Åó„Åü‚ú®üôÜ‚Äç‚ôÄÔ∏è                                                     |\n",
      "|          | Ôºº                                                                                          |\n",
      "|          |                                                                                             |\n",
      "|          | #„Åå„Çì„Å∞„Çå„Éã„ÉÉ„Éù„É≥ üáØüáµüí™                                                                      |\n",
      "|          |                                                                                             |\n",
      "|          | #ÂêâÁî∞Â§ïÊ¢®Ëä± ÈÅ∏Êâã                                                                            |\n",
      "|          | #Èà¥Êú®Â§ïÊπñ ÈÅ∏Êâã                                                                              |\n",
      "|          | #ÂêâÁî∞Áü•ÈÇ£Áæé ÈÅ∏Êâã                                                                            |\n",
      "|          | #Ëó§Êæ§‰∫îÊúà ÈÅ∏Êâã                                                                              |\n",
      "|          | #Áü≥Â¥éÁê¥Áæé ÈÅ∏Êâã                                                                              |\n",
      "|          |                                                                                             |\n",
      "|          | #Beijing202‚Ä¶                                                                                |\n",
      "| 16074    | RT @Japan_Olympic: ‚ï≠‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïÆ                                                          |\n",
      "|          | üìû#ÁæΩÁîüÁµêÂº¶ ÈÅ∏Êâã„Åã„ÇâÈõªË©±‚ÅâÔ∏è                                                                   |\n",
      "|          | ‚ï∞‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïØ                                                                             |\n",
      "|          |                                                                                             |\n",
      "|          | #„Éï„Ç£„ÇÆ„É•„Ç¢„Çπ„Ç±„Éº„Éà Áî∑Â≠ê                                                                    |\n",
      "|          | ÁæΩÁîüÈÅ∏Êâã„Åã„Çâ„ÄéÈõªË©±È¢®„É°„ÉÉ„Çª„Éº„Ç∏„Äèüëã                                                          |\n",
      "|          |                                                                                             |\n",
      "|          | #Beijing2022                                                                                |\n",
      "|          | #TEAMJAPAN                                                                                  |\n",
      "|          | #„Åå„Çì„Å∞„Çå„Éã„ÉÉ‚Ä¶                                                                              |\n",
      "| 11486    | RT @Olympic: 2018 ÌèâÏ∞Ω ÎèôÍ≥ÑÏò¨Î¶ºÌîΩ ÌèêÎßâÏãù Î¨¥ÎåÄÎ•º Íæ∏ÎØº EXOÏùò Í≥µÏó∞ü•∞                           |\n",
      "|          |                                                                                             |\n",
      "|          | 2Ïõî 20Ïùº Î∞§ 9Ïãú(ÌïúÍµ≠ÏãúÍ∞Ñ)Ïóê 2022 Î≤†Ïù¥Ïßï ÎèôÍ≥ÑÏò¨Î¶ºÌîΩ ÌèêÎßâÏãùÏù¥ ÌéºÏ≥êÏßëÎãàÎã§.                     |\n",
      "|          |                                                                                             |\n",
      "|          | #EXO #ÏóëÏÜå #ÌèâÏ∞ΩÏò¨Î¶ºÌîΩ #Î≤†Ïù¥ÏßïÏò¨Î¶ºÌîΩ #Ïò¨Î¶ºÌîΩ #ÌèêÎßâÏãù @Beijing2‚Ä¶                             |\n",
      "| 11171    | RT @Olympics: When @weareoneEXO rocked the PyeongChang2018 #ClosingCeremony üòç üé∂üé§         |\n",
      "|          |                                                                                             |\n",
      "|          | Can't wait for tonight's ceremony! ü§©                                                       |\n",
      "|          |                                                                                             |\n",
      "|          | #EXO | #ÏóëÏÜå | #Grow‚Ä¶                                                                       |\n",
      "| 11104    | RT @Japan_Olympic: #TEAMJAPAN                                                               |\n",
      "|          | #„Éï„Ç£„ÇÆ„É•„Ç¢„Çπ„Ç±„Éº„Éà Áî∑Â≠ê                                                                    |\n",
      "|          | #ÁæΩÁîüÁµêÂº¶ ÈÅ∏Êâã„Åã„ÇâÂøúÊè¥„ÅÑ„Åü„Å†„ÅÑ„ÅüÁöÜ„Åï„Çì„Å∏Âêë„Åë„Å¶„É°„ÉÉ„Çª„Éº„Ç∏„ÅåÂ±ä„Åç„Åæ„Åó„Åü‚ú®                      |\n",
      "|          |                                                                                             |\n",
      "|          | #Beijing2022                                                                                |\n",
      "|          | #„Åå„Çì„Å∞„Çå„Éã„ÉÉ„Éù„É≥                                                                           |\n",
      "|          | #„Ç™„É™„É≥„Éî„ÉÉ„ÇØ https://t.co/VC2dZ‚Ä¶                                                           |\n",
      "| 10636    | RT @tshashin: [Âåó‰∫¨‰∫îËº™ „Éï„Ç£„ÇÆ„É•„Ç¢„Çπ„Ç±„Éº„Éà]                                                 |\n",
      "|          | „Ç®„Ç≠„Ç∑„Éì„Ç∑„Éß„É≥Á∑¥Áøí„ÇíÂâç„Å´„ÇÜ„Å•„Éâ„Ç•„É≥„Éâ„Ç•„É≥„Å´„Å™„Å£„ÅüÁæΩÁîüÁµêÂº¶ÈÅ∏ÊâãÔºàËã•ÊùâÔºâ                        |\n",
      "|          |                                                                                             |\n",
      "|          | Âåó‰∫¨‰∫îËº™ÊÉÖÂ†±„ÅØ‚Üì                                                                             |\n",
      "|          | https://t.co/9PRP63rXJc                                                                     |\n",
      "|          |                                                                                             |\n",
      "|          | #Beijing2022 #Âåó‰∫¨2022 #ÁæΩÁîüÁµêÂº¶ #YuzuruHany‚Ä¶                                               |\n",
      "| 9636     | RT @worldcurling: WHO'S READY FOR THIS @Olympics FINAL?!                                    |\n",
      "|          |                                                                                             |\n",
      "|          | Retweet if you're cheering for JAPAN üáØüáµ                                                     |\n",
      "|          | Favourite‚ù§Ô∏èfor GREAT BRITAIN üá¨üáß                                                              |\n",
      "|          |                                                                                             |\n",
      "|          | #Beiji‚Ä¶                                                                                     |\n",
      "| 8734     | RT @Beijing2022: ‚ú® #YuzuruHanyu #ÁæΩÁîüÁµêÂº¶ kept challenging himself and pushing the limit.  |\n",
      "|          | üí™ We are so touched and inspired by his devotion and‚Ä¶                                      |\n",
      "| 8507     | RT @Japan_Olympic: üáØüáµ‚ùÑÔ∏èüáØüáµ‚ùÑÔ∏èüáØüáµ‚ùÑÔ∏èüáØüáµ‚ùÑÔ∏èüáØüáµ‚ùÑÔ∏èüáØüáµ‚ùÑÔ∏è                                                       |\n",
      "|          | #„Ç´„Éº„É™„É≥„Ç∞ Â•≥Â≠ê                                                                            |\n",
      "|          | #ÈäÄ„É°„ÉÄ„É´ Áç≤Âæó                                                                              |\n",
      "|          | üáØüáµ‚ùÑÔ∏èüáØüáµ‚ùÑÔ∏èüáØüáµ‚ùÑÔ∏èüáØüáµ‚ùÑÔ∏èüáØüáµ‚ùÑÔ∏èüáØüáµ‚ùÑÔ∏è                                                                          |\n",
      "|          |                                                                                             |\n",
      "|          | #Beijing2022                                                                                |\n",
      "|          | #TEAMJAPAN                                                                                  |\n",
      "|          | #„Åå„Çì„Å∞„Çå„Éã„ÉÉ„Éù„É≥                                                                           |\n",
      "|          | #„Ç™„É™„É≥„Éî„ÉÉ„ÇØ http‚Ä¶                                                                         |\n",
      "| 8485     | RT @Japan_Olympic: #„Éï„Ç£„ÇÆ„É•„Ç¢„Çπ„Ç±„Éº„Éà Áî∑Â≠ê                                                 |\n",
      "|          | #ÁæΩÁîüÁµêÂº¶ ÈÅ∏Êâã„Åã„Çâ #„Éê„É¨„É≥„Çø„Ç§„É≥„Éá„Éº „ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏üòò                                         |\n",
      "|          | „Éè„ÉÉ„Éî„Éº„Éê„É¨„É≥„Çø„Ç§„É≥üç´üëã                                                                    |\n",
      "|          |                                                                                             |\n",
      "|          | #ValentinesDay                                                                              |\n",
      "|          | #HappyValentinesDay2022                                                                     |\n",
      "|          | #Beijing2022                                                                                |\n",
      "|          | #TEAMJAP‚Ä¶                                                                                   |\n",
      "+----------+---------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Create a list of all tweets with a retweeted_status key, and index the originator of that tweet and the text.\n",
    "retweets = [\n",
    "            (tweet['retweet_count'],\n",
    "            tweet['text'])\n",
    "            \n",
    "            #Ensure that a retweet exists\n",
    "            for tweet in results                      \n",
    "            ]\n",
    "\n",
    "rtdict = dict(list(zip(tweet_texts, retweets)))\n",
    "def sortRTdict(freqdict):\n",
    "    aux = [(freqdict[key], key) for key in freqdict]\n",
    "    aux.sort()\n",
    "    aux.reverse()\n",
    "    return aux\n",
    "sortedrtdict = sortRTdict(rtdict)\n",
    "rts = []\n",
    "tweets = []\n",
    "\n",
    "for duo in sortedrtdict[:10]:\n",
    "    tweets.append(duo[1])\n",
    "    rts.append(duo[0])\n",
    "\n",
    "pretty_table = PrettyTable(field_names = ['Retweets','Text'])\n",
    "\n",
    "# Sort tweets by descending number of retweets and display the top 10 results in a table.\n",
    "[pretty_table.add_row(row) for row in rts]\n",
    "pretty_table.max_width['Text'] = 200\n",
    "pretty_table.align = 'l'\n",
    "print(pretty_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Find the most popular Tweet Entities in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 hashtags and top 10 user mentions that are the most popular in your collection of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+\n",
      "| Screen Name    | Count |\n",
      "+----------------+-------+\n",
      "| Olympics       |   154 |\n",
      "| weareoneEXO    |    95 |\n",
      "| Beijing2022    |    82 |\n",
      "| TeamGB         |    58 |\n",
      "| gorinjp        |    34 |\n",
      "| jiji_shashinbu |    31 |\n",
      "| mainichiphoto  |    27 |\n",
      "| kyodo_photo    |    25 |\n",
      "| nhk_sports     |    24 |\n",
      "| Japan_Olympic  |    24 |\n",
      "+----------------+-------+\n",
      "+--------------------+-------+\n",
      "| Hashtag            | Count |\n",
      "+--------------------+-------+\n",
      "| Beijing2022        |   602 |\n",
      "| ÁæΩÁîüÁµêÂº¶           |   188 |\n",
      "| „Éï„Ç£„ÇÆ„É•„Ç¢„Çπ„Ç±„Éº„Éà |   159 |\n",
      "| ClosingCeremony    |   145 |\n",
      "| Âåó‰∫¨2022           |   101 |\n",
      "| YuzuruHanyu        |   101 |\n",
      "| EXO                |   100 |\n",
      "| ÏóëÏÜå               |   100 |\n",
      "| Âåó‰∫¨‰∫îËº™           |    94 |\n",
      "| Âåó‰∫¨„Ç™„É™„É≥„Éî„ÉÉ„ÇØ   |    93 |\n",
      "+--------------------+-------+\n"
     ]
    }
   ],
   "source": [
    "# Extract the screen names which appear among the collection of tweets\n",
    "screen_names = [user_mention['screen_name']\n",
    "               for tweet in results\n",
    "                   for user_mention in tweet['entities']['user_mentions']]\n",
    "\n",
    "# Extract the hashtags which appear among the collection of tweets\n",
    "hashtags = [ hashtag['text']\n",
    "           for tweet in results\n",
    "               for hashtag in tweet['entities']['hashtags']]\n",
    "\n",
    "# Simultaneously determine the frequency of screen names/hashtags, and display the top 10 most common in a table.\n",
    "for label, data in (('Screen Name',screen_names),\n",
    "                   ('Hashtag',hashtags)):\n",
    "    pretty_table = PrettyTable(field_names =[label,'Count'])\n",
    "    counter = Counter(data)\n",
    "    [ pretty_table.add_row(entity) for entity in counter.most_common()[:10]]\n",
    "    pretty_table.align[label] ='l'\n",
    "    pretty_table.align['Count'] = 'r'\n",
    "    print(pretty_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Getting \"All\" Friends and \"All\" Followers of a Popular User in Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Choose a popular twitter user who has many followers in the collected tweets of your case topic.\n",
    "* Get the list of all friends and all followers of the twitter user.\n",
    "* Plot 20 out of the followers, plot their ID numbers, and their screen names in a table.\n",
    "* Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers, and their screen names in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4: Domain Question \n",
    "\n",
    "Run some additional experiments with your data to gain familiarity with the twitter data and twitter API.\n",
    "\n",
    "* Come up with a question, which Twitter data could help answer from your collected tweets, based upon your case topic of your chosen public organization, private company, social community, etc., in a domain.\n",
    "* How could Twitter data help that company/organization/community spend its resources to answer the above question?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nteract": {
   "version": "0.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
