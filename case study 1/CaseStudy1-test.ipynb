{"cells":[{"cell_type":"markdown","metadata":{"id":"GgCYbzxaUvqK"},"source":["# Case Study 1 : Collecting Data from Twitter"]},{"cell_type":"markdown","metadata":{"id":"fo1LqIKoUvqN"},"source":["# Problem 1: Sampling Twitter Data with Streaming API about a Certain Topic"]},{"cell_type":"markdown","metadata":{"id":"e43qJo2lUvqN"},"source":["* Select and include a case topic that you are interested in, for example, \"WPI\" or \"Lady Gaga\" or COVID-19.\n","* Use Twitter Streaming API to sample a collection of tweets about this topic in real time. It would be recommended that the number of tweets should be larger than 1000, but smaller than 1 million.\n","* Store the tweets you downloaded into a local file (txt file or json file) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jh2ALDCiUvqO","outputId":"8714ecd2-5d7e-4694-b57d-a20270de1a69"},"outputs":[{"name":"stdout","output_type":"stream","text":["<twitter.api.Twitter object at 0x000001CCB1B69B50>\n","1.1.2\n"]}],"source":["import twitter\n","\n","def oauth_login():\n","    # XXX: Go to http://twitter.com/apps/new to create an app and get values\n","    # for these credentials that you'll need to provide in place of these\n","    # empty string values that are defined as placeholders.\n","    # See https://developer.twitter.com/en/docs/basics/authentication/overview/oauth\n","    # for more information on Twitter's OAuth implementation.\n","    \n","    CONSUMER_KEY = 'OEBQxusAmLaJIP2o3WQTCNxBA'\n","    CONSUMER_SECRET ='rA29WDveS9w50jF9Ke0edA8xuS2oTcehi2Bq6J11cHPwR4RpQE'\n","    OAUTH_TOKEN = '1492269919924195329-KdGOMwMHOJZFKTRvm3ha0zysLcg9ev'\n","    OAUTH_TOKEN_SECRET = 'LQJTZ8HNc5qWleTxhUZYfAy37VJmKH75L9h9OFI2cCRZ0'\n","    \n","    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n","                               CONSUMER_KEY, CONSUMER_SECRET)\n","    \n","    twitter_api = twitter.Twitter(auth=auth)\n","    return twitter_api\n","\n","# Sample usage\n","twitter_api = oauth_login()    \n","\n","# Nothing to see by displaying twitter_api except that it's now a\n","# defined variable\n","\n","print(twitter_api)\n","import flask\n","print(flask.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A_9LxCBiUvqQ"},"outputs":[],"source":["import json\n","import time\n","\n","def twitter_search(twitter_api, q, max_results=1000, **kw):\n","\n","    # See https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets\n","    # and https://developer.twitter.com/en/docs/tweets/search/guides/standard-operators\n","    # for details on advanced search criteria that may be useful for \n","    # keyword arguments\n","    \n","    # See https://dev.twitter.com/docs/api/1.1/get/search/tweets    \n","    search_results = twitter_api.search.tweets(q=q, count=100,lang='en', **kw)\n","    \n","    statuses = search_results['statuses']\n","    \n","    # Iterate through batches of results by following the cursor until we\n","    # reach the desired number of results, keeping in mind that OAuth users\n","    # can \"only\" make 180 search queries per 15-minute interval. See\n","    # https://developer.twitter.com/en/docs/basics/rate-limits\n","    # for details. A reasonable number of results is ~1000, although\n","    # that number of results may not exist for all queries.\n","    \n","    # Enforce a reasonable limit\n","    max_results = min(1000, max_results)\n","    \n","    for _ in range(10): # 10*100 = 1000\n","        try:\n","            next_results = search_results['search_metadata']['next_results']\n","        except KeyError as e: # No more results when next_results doesn't exist\n","            break\n","            \n","        # Create a dictionary from next_results, which has the following form:\n","        # ?max_id=313519052523986943&q=NCAA&include_entities=1\n","        kwargs = dict([ kv.split('=') \n","                        for kv in next_results[1:].split(\"&\") ])\n","        \n","        search_results = twitter_api.search.tweets(**kwargs)\n","        statuses += search_results['statuses']\n","        \n","        if len(statuses) > max_results: \n","            break\n","            \n","    return statuses\n","\n","# Sample usage\n","\n","twitter_api = oauth_login()\n","\n","q = 'Beijing2022'\n","results = twitter_search(twitter_api, q, max_results=1000)\n","        \n","# Show one sample search result by slicing the list...\n","data = json.dumps(results, indent=1)\n","\n","file = open('extracted_tweets_beijing_2022_final.txt', 'w')\n","file.write(data)\n","file.close()"]},{"cell_type":"markdown","metadata":{"id":"Fa817kXqUvqR"},"source":["# Problem 2: Analyzing Tweets and Tweet Entities with Frequency Analysis\n","\n","**1. Word Count:** \n","* Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets. \n","* Plot a table of the top 30 words with their counts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QMlTAQNAUvqS","outputId":"c125de54-3ad5-4c19-b0f6-3d2f225da35d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of Tweets: 1100\n","+------------+-------+\n","| Word       | Count |\n","+------------+-------+\n","| Olympic    |   166 |\n","| Winter     |   135 |\n","| figure     |   132 |\n","| skating    |    80 |\n","| medals     |    74 |\n","| Yuzuru     |    71 |\n","| gold       |    70 |\n","| Olympics   |    66 |\n","| first      |    61 |\n","| one        |    57 |\n","| together   |    56 |\n","| Gala       |    56 |\n","| home       |    55 |\n","| medal      |    55 |\n","| Skating    |    55 |\n","| Figure     |    54 |\n","| Wearing    |    53 |\n","| hats       |    53 |\n","| performing |    53 |\n","| Hany‚Ä¶      |    53 |\n","| team       |    52 |\n","| became     |    47 |\n","| flight     |    46 |\n","| Games      |    46 |\n","| athletes   |    46 |\n","| Extra      |    45 |\n","| baggage    |    45 |\n","| needed     |    45 |\n","| today‚Ä¶     |    45 |\n","| ü•áü•à       |    45 |\n","+------------+-------+\n"]}],"source":["from collections import Counter\n","from prettytable import PrettyTable\n","import nltk\n","\n","tweet_texts = [ tweet['text'] \n","                 for tweet in results ]\n","words = [ word \n","          for tweet in tweet_texts \n","              for word in tweet.split()\n","                 if word not in ['RT', '&amp;', '|', '-'] and '#' not in word and '@' not in word# filter out RT and ampersand\n","        ]\n","\n","# Use the natural language toolkit to eliminate stop words\n","\n","# nltk.download('stopwords') # download stop words if you do not have it\n","stop_words = nltk.corpus.stopwords.words('english')\n","stop_words_french = nltk.corpus.stopwords.words('french')\n","stop_words_spanish = nltk.corpus.stopwords.words('spanish')\n","non_stop_words = [w for w in words if w.lower() not in stop_words + stop_words_french + stop_words_spanish]\n","\n","# frequency of words\n","count = Counter(non_stop_words).most_common()\n","\n","# table of the top 30 words with their counts\n","pretty_table = PrettyTable(field_names=['Word', 'Count']) \n","[ pretty_table.add_row(w) for w in count[:30] ]\n","pretty_table.align['Word'] = 'l'\n","pretty_table.align['Count'] = 'r'\n","print(\"Number of Tweets: \" + str(len(tweet_texts)))\n","print(pretty_table)"]},{"cell_type":"markdown","metadata":{"id":"DSO6C1sFUvqU"},"source":["**2. Find the most popular tweets in your collection of tweets**\n","\n","Please plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ghf0sTCtUvqV","outputId":"327e1add-9f1d-4208-e818-cd9abde1142e"},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------+----------------------------------------------------------------------------------------------------------------------------------------------+\n","| Retweets | Text                                                                                                                                         |\n","+----------+----------------------------------------------------------------------------------------------------------------------------------------------+\n","| 14597    | RT @Olympics: When @weareoneEXO rocked the PyeongChang2018 #ClosingCeremony üòç üé∂üé§                                                          |\n","|          |                                                                                                                                              |\n","|          | Can't wait for tonight's ceremony! ü§©                                                                                                        |\n","|          |                                                                                                                                              |\n","|          | #EXO | #ÏóëÏÜå | #Grow‚Ä¶                                                                                                                        |\n","| 6950     | RT @MsMelChen: China is requiring a mandatory app that is ostensibly for \"health monitoring\" for all Beijing Olympics participants, media a‚Ä¶ |\n","| 3706     | RT @Olympics: Gift time! Wang Shiyue and Liu Xinyu made sure Hanyu Yuzuru did not leave Beijing without a limited edition #BingDwenDwen üò≠‚Ä¶  |\n","| 2360     | RT @Olympics: HISTORY MADE!                                                                                                                  |\n","|          |                                                                                                                                              |\n","|          | 15-year-old Kamila Valieva becomes the first woman to land a quadruple jump at an Olympic Games. ü§Ø                                          |\n","|          |                                                                                                                                              |\n","|          | #Beijing20‚Ä¶                                                                                                                                  |\n","| 1997     | RT @Beijing2022: üíïFigure Skaters' party time with #BingDwenDwen! Let's dance!                                                               |\n","|          |                                                                                                                                              |\n","|          | #Beijing2022 #ClosingCeremony #TogetherForASharedFuture #Oly‚Ä¶                                                                                |\n","| 1863     | RT @Olympics: Sui Wenjing and Han Cong (People's Republic of China) win the pair skating #Gold medal, becoming the first Chinese #FigureSka‚Ä¶ |\n","| 1587     | RT @IIHFHockey: HISTORY MADE! For the first time ever, @leijonat has won a gold medal in #Olympic #icehockey! Congrats!üá´üáÆü•á                  |\n","|          |                                                                                                                                              |\n","|          | #Beijing2022 #O‚Ä¶                                                                                                                             |\n","| 1404     | RT @milanocortina26: WE ARE NEXT @Olympics @Beijing2022 #milanocortina2026 https://t.co/JqTAbP83ix                                           |\n","| 1388     | RT @SpokespersonCHN: Wearing #BingDwenDwen hats and performing figure skating together at the Figure Skating Gala #Beijing2022, Yuzuru Hany‚Ä¶ |\n","| 1385     | RT @Olympics: \"He keeps moving the sport of men's figure skating forward.\"                                                                   |\n","|          |                                                                                                                                              |\n","|          | Hanyu Yuzuru's coach Brian Orser opens up about his charge's go‚Ä¶                                                                             |\n","+----------+----------------------------------------------------------------------------------------------------------------------------------------------+\n"]}],"source":["# Create a list of all tweets with a retweeted_status key, and index the originator of that tweet and the text.\n","retweets = [\n","            (tweet['retweet_count'],\n","             tweet['text'])\n","            for tweet in results                      \n","            ]\n","\n","#del list\n","rtdict = dict(list(zip(tweet_texts, retweets)))\n","def sortRTdict(freqdict):\n","    aux = [(freqdict[key], key) for key in freqdict]\n","    aux.sort()\n","    aux.reverse()\n","    return aux\n","sortedrtdict = sortRTdict(rtdict)\n","rts = []\n","tweets = []\n","\n","for duo in sortedrtdict[:10]:\n","    tweets.append(duo[1])\n","    rts.append(duo[0])\n","\n","pretty_table = PrettyTable(field_names = ['Retweets','Text'])\n","\n","# Sort tweets by descending number of retweets and display the top 10 results in a table.\n","[pretty_table.add_row(row) for row in rts]\n","pretty_table.max_width['Text'] = 200\n","pretty_table.align = 'l'\n","print(pretty_table)"]},{"cell_type":"markdown","metadata":{"id":"5Z_rLXbnUvqW"},"source":["**3. Find the most popular Tweet Entities in your collection of tweets**\n","\n","Please plot a table of the top 10 hashtags and top 10 user mentions that are the most popular in your collection of tweets."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KvSWxepsUvqX","outputId":"2e0ee289-f589-45c4-c709-b294649d5598"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------+-------+\n","| Screen Name     | Count |\n","+-----------------+-------+\n","| Beijing2022     |   131 |\n","| Olympics        |   101 |\n","| TeamGB          |    73 |\n","| USFigureSkating |    57 |\n","| SpokespersonCHN |    55 |\n","| nathanwchen     |    37 |\n","| billmaher       |    34 |\n","| nytimes         |    33 |\n","| CarlZha         |    32 |\n","| weareoneEXO     |    32 |\n","+-----------------+-------+\n","+--------------------------+-------+\n","| Hashtag                  | Count |\n","+--------------------------+-------+\n","| Beijing2022              |   577 |\n","| BingDwenDwen             |   126 |\n","| Olympics                 |    85 |\n","| ClosingCeremony          |    77 |\n","| WinterOlympics           |    75 |\n","| TeamGB                   |    54 |\n","| MedalistMonday           |    37 |\n","| TogetherForASharedFuture |    34 |\n","| EXO                      |    32 |\n","| ÏóëÏÜå                     |    32 |\n","+--------------------------+-------+\n"]}],"source":["# Extract the screen names which appear among the collection of tweets\n","screen_names = [user_mention['screen_name']\n","               for tweet in results\n","                   for user_mention in tweet['entities']['user_mentions']]\n","\n","# Extract the hashtags which appear among the collection of tweets\n","hashtags = [ hashtag['text']\n","           for tweet in results\n","               for hashtag in tweet['entities']['hashtags']]\n","\n","# Simultaneously determine the frequency of screen names/hashtags, and display the top 10 most common in a table.\n","for label, data in (('Screen Name',screen_names),\n","                   ('Hashtag',hashtags)):\n","    pretty_table = PrettyTable(field_names =[label,'Count'])\n","    counter = Counter(data)\n","    [ pretty_table.add_row(entity) for entity in counter.most_common()[:10]]\n","    pretty_table.align[label] ='l'\n","    pretty_table.align['Count'] = 'r'\n","    print(pretty_table)"]},{"cell_type":"markdown","metadata":{"id":"zP-G0SFDUvqY"},"source":["# Problem 3: Getting \"All\" Friends and \"All\" Followers of a Popular User in Twitter"]},{"cell_type":"markdown","metadata":{"id":"vrT2U69LUvqY"},"source":["* Choose a popular twitter user who has many followers in the collected tweets of your case topic.\n","* Get the list of all friends and all followers of the twitter user.\n","* Plot 20 out of the followers, plot their ID numbers, and their screen names in a table.\n","* Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers, and their screen names in a table."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XmjaYC21UvqY","outputId":"93df7a70-897a-48a3-dea8-988ea283c775"},"outputs":[{"name":"stdout","output_type":"stream","text":["rodmickleburgh\n"]}],"source":["import tweepy\n","  \n","# assign the values accordingly\n","consumer_key = 'OEBQxusAmLaJIP2o3WQTCNxBA'\n","consumer_secret = 'rA29WDveS9w50jF9Ke0edA8xuS2oTcehi2Bq6J11cHPwR4RpQE'\n","access_token = '1492269919924195329-KdGOMwMHOJZFKTRvm3ha0zysLcg9ev'\n","access_token_secret = 'LQJTZ8HNc5qWleTxhUZYfAy37VJmKH75L9h9OFI2cCRZ0'\n","  \n","# authorization of consumer key and consumer secret\n","auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n","  \n","# set access to user's access key and access secret \n","auth.set_access_token(access_token, access_token_secret)\n","  \n","# calling the api \n","api = tweepy.API(auth)\n","\n","name = [ tweet['user']['screen_name'] \n","                for tweet in results ]\n","\n","count = []\n","for i in range(100):\n","    user = api.get_user(screen_name= name[i])\n","    followers_count = user.followers_count\n","    friends_count = user.friends_count\n","    count.append(followers_count+friends_count)\n","top3 = [count.index(x) for x in sorted(count, reverse=True)[:4]]\n","i = top3[3]\n","user = api.get_user(screen_name= name[i])\n","\n","# screen name of the user\n","print(name[i])\n","name = name[i]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ys817VkJUvqZ"},"outputs":[],"source":["# getting the friends list\n","friends = api.get_friend_ids(screen_name = name, count = 300)\n","\n","friend_list = []    \n","for friend in friends:\n","    friend_list.append(api.get_user(user_id = friend).screen_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"BRtQO6lLUvqZ","outputId":"16c8ec53-f3b0-4f33-8f4e-a1fa29423312"},"outputs":[{"name":"stdout","output_type":"stream","text":["300\n"]}],"source":["print(len(friend_list))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ETc7xBM_UvqZ","outputId":"bd99d60e-bb23-47f1-803e-91471eb7090b"},"outputs":[{"name":"stdout","output_type":"stream","text":["                     ID      Screen name\n","0             593175545        missprill\n","1             440389866      DavidSpaner\n","2             130120037      PippaCrerar\n","3              56556395         ann_rees\n","4   1015339707343835136    Trish09071900\n","5             299820130   TriciaLockwood\n","6             385229000       MJSchulman\n","7             159128818   lynnmilesmusic\n","8             170336862      rosecousins\n","9              19657809       maxfawcett\n","10  1296239665377206273     KathyCalder6\n","11             18980055        cbcradioq\n","12           2975475327     dwebsterhist\n","13            612114921      DanielKalla\n","14  1194627927272542209  leylahfernandez\n","15           2252615726        ca_sayers\n","16             18440301      PennyDaflos\n","17            380900984       olddanbook\n","18             18788452            lslot\n","19            340466229     IAmAmnaNawaz\n"]}],"source":["# Plot 20 out of the friend, plot their ID numbers, and their screen names in a table.\n","dfriend = []\n","for i in range(20):\n","    dfriend.append([friends[i],friend_list[i]])\n","dfri = pd.DataFrame(dfriend,columns=['ID', 'Screen name'])\n","print(dfri)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RLTYXfQ3Uvqa"},"outputs":[],"source":["# getting the followers list\n","followers = api.get_follower_ids(screen_name = name, count = 300)\n","\n","follower_list = []    \n","for follower in followers:\n","    follower_list.append(api.get_user(user_id = follower).screen_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Krpr6CQ6Uvqa","outputId":"b1487170-7450-4b3b-c5de-28580c3c369f"},"outputs":[{"name":"stdout","output_type":"stream","text":["                     ID      Screen name\n","0   1494718822087024645         CBernent\n","1   1495809219202732038  plumber_another\n","2            3108888065     hnstCanadian\n","3             261920529     roguechimp99\n","4   1494424236756291585  paulmil91849591\n","5   1486528713718128648  WealthExecutive\n","6            1279036994    AmandaMechele\n","7   1485409328026640384          RoryLew\n","8   1495229426669342724    Baboucarr1111\n","9            2286487057        AJandTara\n","10             43053298    Miss_T_tweets\n","11  1488273192682590210  Dontsweatthesm5\n","12  1407158788910682114  MarkZuckerpunch\n","13  1439957711173660672   PapyrusBrigade\n","14  1489964710111981576  PennyHa98551852\n","15  1455963692672053250  CityHallWchWchr\n","16            272969211      NormanRoots\n","17            792615860    drivercom99in\n","18  1258762616790331394    10minreviewer\n","19            375258014  DavidChenTweets\n"]}],"source":["import pandas as pd\n","\n","# Plot 20 out of the followers, plot their ID numbers, and their screen names in a table.\n","dfollower = []\n","for i in range(20):\n","    dfollower.append([followers[i],follower_list[i]])\n","dfoll = pd.DataFrame(dfollower,columns=['ID', 'Screen name'])\n","print(dfoll)"]},{"cell_type":"markdown","metadata":{"id":"xQ7IBSnvUvqa"},"source":["* Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GK1_9iC8Uvqa","outputId":"4c5aa43c-3c5b-4582-8b8b-e4bfe738612b"},"outputs":[{"name":"stdout","output_type":"stream","text":["          ID  Screen name\n","0  440389866  DavidSpaner\n"]}],"source":["df1 = pd.DataFrame(followers,columns=[\"ID\"])\n","df2 = pd.DataFrame(friends,columns=[\"ID\"])\n","df3 = df1.merge(df2, how = 'inner' ,indicator=False)\n","\n","mutual_names = []\n","for f in df3[\"ID\"]:\n","    mutual_names.append( api.get_user(user_id = f).screen_name)\n","\n","mutuals = []\n","for i in range(len(df3[\"ID\"])):\n","    mutuals.append([df3[\"ID\"][i], mutual_names[i]])\n","mutualsPD = pd.DataFrame(mutuals,columns=['ID', 'Screen name'])\n","print(mutualsPD)"]},{"cell_type":"markdown","metadata":{"id":"NnfCGWzcUvqb"},"source":["# Problem 4: Domain Question \n","\n","Run some additional experiments with your data to gain familiarity with the twitter data and twitter API.\n","\n","* Come up with a question, which Twitter data could help answer from your collected tweets, based upon your case topic of your chosen public organization, private company, social community, etc., in a domain.\n","* How could Twitter data help that company/organization/community spend its resources to answer the above question?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a7RtjURMUvqb","outputId":"433dacd1-ed92-415a-970c-0721978d0fd1"},"outputs":[{"name":"stdout","output_type":"stream","text":["+------------------+-------+\n","|     Location     | Count |\n","+------------------+-------+\n","| West Newbury, MA |    26 |\n","|    Australia     |    22 |\n","|  United Kingdom  |    11 |\n","+------------------+-------+\n"]}],"source":["countries = [ tweet['user']['location'] \n","                for tweet in results ]\n","\n","# frequency of countries\n","count = Counter(countries).most_common()\n","\n","# table of the top 30 words with their counts\n","pretty_table = PrettyTable(field_names=['Location', 'Count']) \n","[ pretty_table.add_row(w) for w in count[1:4] ]\n","pretty_table.align['Word'] = 'l'\n","pretty_table.align['Count'] = 'r'\n","print(pretty_table)"]}],"metadata":{"anaconda-cloud":{},"kernel_info":{"name":"python3"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"nteract":{"version":"0.2.0"},"colab":{"name":"CaseStudy1-test.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}