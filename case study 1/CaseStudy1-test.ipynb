{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 1 : Collecting Data from Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Sampling Twitter Data with Streaming API about a Certain Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select and include a case topic that you are interested in, for example, \"WPI\" or \"Lady Gaga\" or COVID-19.\n",
    "* Use Twitter Streaming API to sample a collection of tweets about this topic in real time. It would be recommended that the number of tweets should be larger than 1000, but smaller than 1 million.\n",
    "* Store the tweets you downloaded into a local file (txt file or json file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<twitter.api.Twitter object at 0x000001E9A720A490>\n",
      "1.1.2\n"
     ]
    }
   ],
   "source": [
    "import twitter\n",
    "\n",
    "def oauth_login():\n",
    "    # XXX: Go to http://twitter.com/apps/new to create an app and get values\n",
    "    # for these credentials that you'll need to provide in place of these\n",
    "    # empty string values that are defined as placeholders.\n",
    "    # See https://developer.twitter.com/en/docs/basics/authentication/overview/oauth\n",
    "    # for more information on Twitter's OAuth implementation.\n",
    "    \n",
    "    CONSUMER_KEY = 'OEBQxusAmLaJIP2o3WQTCNxBA'\n",
    "    CONSUMER_SECRET ='rA29WDveS9w50jF9Ke0edA8xuS2oTcehi2Bq6J11cHPwR4RpQE'\n",
    "    OAUTH_TOKEN = '1492269919924195329-KdGOMwMHOJZFKTRvm3ha0zysLcg9ev'\n",
    "    OAUTH_TOKEN_SECRET = 'LQJTZ8HNc5qWleTxhUZYfAy37VJmKH75L9h9OFI2cCRZ0'\n",
    "    \n",
    "    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                               CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    \n",
    "    twitter_api = twitter.Twitter(auth=auth)\n",
    "    return twitter_api\n",
    "\n",
    "# Sample usage\n",
    "twitter_api = oauth_login()    \n",
    "\n",
    "# Nothing to see by displaying twitter_api except that it's now a\n",
    "# defined variable\n",
    "\n",
    "print(twitter_api)\n",
    "import flask\n",
    "print(flask.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "def twitter_search(twitter_api, q, max_results=1000, **kw):\n",
    "\n",
    "    # See https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets\n",
    "    # and https://developer.twitter.com/en/docs/tweets/search/guides/standard-operators\n",
    "    # for details on advanced search criteria that may be useful for \n",
    "    # keyword arguments\n",
    "    \n",
    "    # See https://dev.twitter.com/docs/api/1.1/get/search/tweets    \n",
    "    search_results = twitter_api.search.tweets(q=q, count=100, **kw)\n",
    "    \n",
    "    statuses = search_results['statuses']\n",
    "    \n",
    "    # Iterate through batches of results by following the cursor until we\n",
    "    # reach the desired number of results, keeping in mind that OAuth users\n",
    "    # can \"only\" make 180 search queries per 15-minute interval. See\n",
    "    # https://developer.twitter.com/en/docs/basics/rate-limits\n",
    "    # for details. A reasonable number of results is ~1000, although\n",
    "    # that number of results may not exist for all queries.\n",
    "    \n",
    "    # Enforce a reasonable limit\n",
    "    max_results = min(1000, max_results)\n",
    "    \n",
    "    for _ in range(10): # 10*100 = 1000\n",
    "        try:\n",
    "            next_results = search_results['search_metadata']['next_results']\n",
    "        except KeyError as e: # No more results when next_results doesn't exist\n",
    "            break\n",
    "            \n",
    "        # Create a dictionary from next_results, which has the following form:\n",
    "        # ?max_id=313519052523986943&q=NCAA&include_entities=1\n",
    "        kwargs = dict([ kv.split('=') \n",
    "                        for kv in next_results[1:].split(\"&\") ])\n",
    "        \n",
    "        search_results = twitter_api.search.tweets(**kwargs)\n",
    "        statuses += search_results['statuses']\n",
    "        \n",
    "        if len(statuses) > max_results: \n",
    "            break\n",
    "            \n",
    "    return statuses\n",
    "\n",
    "# Sample usage\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "q = 'Beijing2022'\n",
    "results = twitter_search(twitter_api, q, max_results=1000)\n",
    "        \n",
    "# Show one sample search result by slicing the list...\n",
    "data = json.dumps(results, indent=1)\n",
    "\n",
    "file = open('extracted_tweets_beijing_2022_final.txt', 'w')\n",
    "file.write(data)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Analyzing Tweets and Tweet Entities with Frequency Analysis\n",
    "\n",
    "**1. Word Count:** \n",
    "* Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets. \n",
    "* Plot a table of the top 30 words with their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------+\n",
      "| Word                | Count |\n",
      "+---------------------+-------+\n",
      "| #Beijing2022        |   539 |\n",
      "| #ç¾½ç”Ÿçµå¼¦           |   181 |\n",
      "| #ClosingCeremony    |   145 |\n",
      "| de                  |   139 |\n",
      "| @Olympics:          |   134 |\n",
      "| #ãƒ•ã‚£ã‚®ãƒ¥ã‚¢ã‚¹ã‚±ãƒ¼ãƒˆ |   122 |\n",
      "| ğŸ˜                  |   102 |\n",
      "| ğŸ¤©                  |   102 |\n",
      "| #åŒ—äº¬2022           |   101 |\n",
      "| #EXO                |   100 |\n",
      "| #ì—‘ì†Œ               |   100 |\n",
      "| wait                |    97 |\n",
      "| #YuzuruHanyu        |    96 |\n",
      "| Can't               |    96 |\n",
      "| tonight's           |    96 |\n",
      "| @weareoneEXO        |    95 |\n",
      "| rocked              |    95 |\n",
      "| PyeongChang2018     |    95 |\n",
      "| ğŸ¶ğŸ¤                |    95 |\n",
      "| ceremony!           |    95 |\n",
      "| #Growâ€¦              |    95 |\n",
      "| Olympic             |    76 |\n",
      "| é¸æ‰‹                |    55 |\n",
      "| #TeamGB             |    51 |\n",
      "| ã‚¨ã‚­ã‚·ãƒ“ã‚·ãƒ§ãƒ³      |    50 |\n",
      "| #åŒ—äº¬äº”è¼ª           |    48 |\n",
      "| #åŒ—äº¬ã‚ªãƒªãƒ³ãƒ”ãƒƒã‚¯   |    46 |\n",
      "| medal               |    46 |\n",
      "| #Olympics           |    45 |\n",
      "| la                  |    45 |\n",
      "+---------------------+-------+\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from prettytable import PrettyTable\n",
    "import nltk\n",
    "\n",
    "tweet_texts = [ tweet['text'] \n",
    "                 for tweet in results ]\n",
    "words = [ word \n",
    "          for tweet in tweet_texts \n",
    "              for word in tweet.split()\n",
    "                 if word not in ['RT', '&amp;', '|'] # filter out RT and ampersand\n",
    "        ]\n",
    "\n",
    "# Use the natural language toolkit to eliminate stop words\n",
    "\n",
    "# nltk.download('stopwords') # download stop words if you do not have it\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "non_stop_words = [w for w in words if w.lower() not in stop_words]\n",
    "\n",
    "# frequency of words\n",
    "count = Counter(non_stop_words).most_common()\n",
    "\n",
    "# table of the top 30 words with their counts\n",
    "pretty_table = PrettyTable(field_names=['Word', 'Count']) \n",
    "[ pretty_table.add_row(w) for w in count[:30] ]\n",
    "pretty_table.align['Word'] = 'l'\n",
    "pretty_table.align['Count'] = 'r'\n",
    "print(pretty_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Find the most popular tweets in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------------------------------------------------------------------------------+\n",
      "| Retweets | Text                                                                                        |\n",
      "+----------+---------------------------------------------------------------------------------------------+\n",
      "| 18641    | RT @Japan_Olympic: ï¼                                                                       |\n",
      "|          | æ±ºå‹ã¯æ˜æ—¥ï¼ #ã‚«ãƒ¼ãƒªãƒ³ã‚° å¥³å­ğŸ¥Œ                                                             |\n",
      "|          | é¸æ‰‹ãŸã¡ã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå±Šãã¾ã—ãŸâœ¨ğŸ™†â€â™€ï¸                                                     |\n",
      "|          | ï¼¼                                                                                          |\n",
      "|          |                                                                                             |\n",
      "|          | #ãŒã‚“ã°ã‚Œãƒ‹ãƒƒãƒãƒ³ ğŸ‡¯ğŸ‡µğŸ’ª                                                                      |\n",
      "|          |                                                                                             |\n",
      "|          | #å‰ç”°å¤•æ¢¨èŠ± é¸æ‰‹                                                                            |\n",
      "|          | #éˆ´æœ¨å¤•æ¹– é¸æ‰‹                                                                              |\n",
      "|          | #å‰ç”°çŸ¥é‚£ç¾ é¸æ‰‹                                                                            |\n",
      "|          | #è—¤æ¾¤äº”æœˆ é¸æ‰‹                                                                              |\n",
      "|          | #çŸ³å´ç´ç¾ é¸æ‰‹                                                                              |\n",
      "|          |                                                                                             |\n",
      "|          | #Beijing202â€¦                                                                                |\n",
      "| 16074    | RT @Japan_Olympic: â•­â”â”â”â”â”â”â”â”â”â”â”â”â”â•®                                                          |\n",
      "|          | ğŸ“#ç¾½ç”Ÿçµå¼¦ é¸æ‰‹ã‹ã‚‰é›»è©±â‰ï¸                                                                   |\n",
      "|          | â•°â”â”â”â”â”â”â”â”â”â”â”â”â”â•¯                                                                             |\n",
      "|          |                                                                                             |\n",
      "|          | #ãƒ•ã‚£ã‚®ãƒ¥ã‚¢ã‚¹ã‚±ãƒ¼ãƒˆ ç”·å­                                                                    |\n",
      "|          | ç¾½ç”Ÿé¸æ‰‹ã‹ã‚‰ã€é›»è©±é¢¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€ğŸ‘‹                                                          |\n",
      "|          |                                                                                             |\n",
      "|          | #Beijing2022                                                                                |\n",
      "|          | #TEAMJAPAN                                                                                  |\n",
      "|          | #ãŒã‚“ã°ã‚Œãƒ‹ãƒƒâ€¦                                                                              |\n",
      "| 11486    | RT @Olympic: 2018 í‰ì°½ ë™ê³„ì˜¬ë¦¼í”½ íë§‰ì‹ ë¬´ëŒ€ë¥¼ ê¾¸ë¯¼ EXOì˜ ê³µì—°ğŸ¥°                           |\n",
      "|          |                                                                                             |\n",
      "|          | 2ì›” 20ì¼ ë°¤ 9ì‹œ(í•œêµ­ì‹œê°„)ì— 2022 ë² ì´ì§• ë™ê³„ì˜¬ë¦¼í”½ íë§‰ì‹ì´ í¼ì³ì§‘ë‹ˆë‹¤.                     |\n",
      "|          |                                                                                             |\n",
      "|          | #EXO #ì—‘ì†Œ #í‰ì°½ì˜¬ë¦¼í”½ #ë² ì´ì§•ì˜¬ë¦¼í”½ #ì˜¬ë¦¼í”½ #íë§‰ì‹ @Beijing2â€¦                             |\n",
      "| 11171    | RT @Olympics: When @weareoneEXO rocked the PyeongChang2018 #ClosingCeremony ğŸ˜ ğŸ¶ğŸ¤         |\n",
      "|          |                                                                                             |\n",
      "|          | Can't wait for tonight's ceremony! ğŸ¤©                                                       |\n",
      "|          |                                                                                             |\n",
      "|          | #EXO | #ì—‘ì†Œ | #Growâ€¦                                                                       |\n",
      "| 11104    | RT @Japan_Olympic: #TEAMJAPAN                                                               |\n",
      "|          | #ãƒ•ã‚£ã‚®ãƒ¥ã‚¢ã‚¹ã‚±ãƒ¼ãƒˆ ç”·å­                                                                    |\n",
      "|          | #ç¾½ç”Ÿçµå¼¦ é¸æ‰‹ã‹ã‚‰å¿œæ´ã„ãŸã ã„ãŸçš†ã•ã‚“ã¸å‘ã‘ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå±Šãã¾ã—ãŸâœ¨                      |\n",
      "|          |                                                                                             |\n",
      "|          | #Beijing2022                                                                                |\n",
      "|          | #ãŒã‚“ã°ã‚Œãƒ‹ãƒƒãƒãƒ³                                                                           |\n",
      "|          | #ã‚ªãƒªãƒ³ãƒ”ãƒƒã‚¯ https://t.co/VC2dZâ€¦                                                           |\n",
      "| 10636    | RT @tshashin: [åŒ—äº¬äº”è¼ª ãƒ•ã‚£ã‚®ãƒ¥ã‚¢ã‚¹ã‚±ãƒ¼ãƒˆ]                                                 |\n",
      "|          | ã‚¨ã‚­ã‚·ãƒ“ã‚·ãƒ§ãƒ³ç·´ç¿’ã‚’å‰ã«ã‚†ã¥ãƒ‰ã‚¥ãƒ³ãƒ‰ã‚¥ãƒ³ã«ãªã£ãŸç¾½ç”Ÿçµå¼¦é¸æ‰‹ï¼ˆè‹¥æ‰ï¼‰                        |\n",
      "|          |                                                                                             |\n",
      "|          | åŒ—äº¬äº”è¼ªæƒ…å ±ã¯â†“                                                                             |\n",
      "|          | https://t.co/9PRP63rXJc                                                                     |\n",
      "|          |                                                                                             |\n",
      "|          | #Beijing2022 #åŒ—äº¬2022 #ç¾½ç”Ÿçµå¼¦ #YuzuruHanyâ€¦                                               |\n",
      "| 9636     | RT @worldcurling: WHO'S READY FOR THIS @Olympics FINAL?!                                    |\n",
      "|          |                                                                                             |\n",
      "|          | Retweet if you're cheering for JAPAN ğŸ‡¯ğŸ‡µ                                                     |\n",
      "|          | Favouriteâ¤ï¸for GREAT BRITAIN ğŸ‡¬ğŸ‡§                                                              |\n",
      "|          |                                                                                             |\n",
      "|          | #Beijiâ€¦                                                                                     |\n",
      "| 8734     | RT @Beijing2022: âœ¨ #YuzuruHanyu #ç¾½ç”Ÿçµå¼¦ kept challenging himself and pushing the limit.  |\n",
      "|          | ğŸ’ª We are so touched and inspired by his devotion andâ€¦                                      |\n",
      "| 8507     | RT @Japan_Olympic: ğŸ‡¯ğŸ‡µâ„ï¸ğŸ‡¯ğŸ‡µâ„ï¸ğŸ‡¯ğŸ‡µâ„ï¸ğŸ‡¯ğŸ‡µâ„ï¸ğŸ‡¯ğŸ‡µâ„ï¸ğŸ‡¯ğŸ‡µâ„ï¸                                                       |\n",
      "|          | #ã‚«ãƒ¼ãƒªãƒ³ã‚° å¥³å­                                                                            |\n",
      "|          | #éŠ€ãƒ¡ãƒ€ãƒ« ç²å¾—                                                                              |\n",
      "|          | ğŸ‡¯ğŸ‡µâ„ï¸ğŸ‡¯ğŸ‡µâ„ï¸ğŸ‡¯ğŸ‡µâ„ï¸ğŸ‡¯ğŸ‡µâ„ï¸ğŸ‡¯ğŸ‡µâ„ï¸ğŸ‡¯ğŸ‡µâ„ï¸                                                                          |\n",
      "|          |                                                                                             |\n",
      "|          | #Beijing2022                                                                                |\n",
      "|          | #TEAMJAPAN                                                                                  |\n",
      "|          | #ãŒã‚“ã°ã‚Œãƒ‹ãƒƒãƒãƒ³                                                                           |\n",
      "|          | #ã‚ªãƒªãƒ³ãƒ”ãƒƒã‚¯ httpâ€¦                                                                         |\n",
      "| 8485     | RT @Japan_Olympic: #ãƒ•ã‚£ã‚®ãƒ¥ã‚¢ã‚¹ã‚±ãƒ¼ãƒˆ ç”·å­                                                 |\n",
      "|          | #ç¾½ç”Ÿçµå¼¦ é¸æ‰‹ã‹ã‚‰ #ãƒãƒ¬ãƒ³ã‚¿ã‚¤ãƒ³ãƒ‡ãƒ¼ ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ğŸ˜˜                                         |\n",
      "|          | ãƒãƒƒãƒ”ãƒ¼ãƒãƒ¬ãƒ³ã‚¿ã‚¤ãƒ³ğŸ«ğŸ‘‹                                                                    |\n",
      "|          |                                                                                             |\n",
      "|          | #ValentinesDay                                                                              |\n",
      "|          | #HappyValentinesDay2022                                                                     |\n",
      "|          | #Beijing2022                                                                                |\n",
      "|          | #TEAMJAPâ€¦                                                                                   |\n",
      "+----------+---------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Create a list of all tweets with a retweeted_status key, and index the originator of that tweet and the text.\n",
    "retweets = [\n",
    "            (tweet['retweet_count'],\n",
    "            tweet['text'])\n",
    "            \n",
    "            #Ensure that a retweet exists\n",
    "            for tweet in results                      \n",
    "            ]\n",
    "\n",
    "rtdict = dict(list(zip(tweet_texts, retweets)))\n",
    "def sortRTdict(freqdict):\n",
    "    aux = [(freqdict[key], key) for key in freqdict]\n",
    "    aux.sort()\n",
    "    aux.reverse()\n",
    "    return aux\n",
    "sortedrtdict = sortRTdict(rtdict)\n",
    "rts = []\n",
    "tweets = []\n",
    "\n",
    "for duo in sortedrtdict[:10]:\n",
    "    tweets.append(duo[1])\n",
    "    rts.append(duo[0])\n",
    "\n",
    "pretty_table = PrettyTable(field_names = ['Retweets','Text'])\n",
    "\n",
    "# Sort tweets by descending number of retweets and display the top 10 results in a table.\n",
    "[pretty_table.add_row(row) for row in rts]\n",
    "pretty_table.max_width['Text'] = 200\n",
    "pretty_table.align = 'l'\n",
    "print(pretty_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Find the most popular Tweet Entities in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 hashtags and top 10 user mentions that are the most popular in your collection of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+\n",
      "| Screen Name    | Count |\n",
      "+----------------+-------+\n",
      "| Olympics       |   154 |\n",
      "| weareoneEXO    |    95 |\n",
      "| Beijing2022    |    82 |\n",
      "| TeamGB         |    58 |\n",
      "| gorinjp        |    34 |\n",
      "| jiji_shashinbu |    31 |\n",
      "| mainichiphoto  |    27 |\n",
      "| kyodo_photo    |    25 |\n",
      "| nhk_sports     |    24 |\n",
      "| Japan_Olympic  |    24 |\n",
      "+----------------+-------+\n",
      "+--------------------+-------+\n",
      "| Hashtag            | Count |\n",
      "+--------------------+-------+\n",
      "| Beijing2022        |   602 |\n",
      "| ç¾½ç”Ÿçµå¼¦           |   188 |\n",
      "| ãƒ•ã‚£ã‚®ãƒ¥ã‚¢ã‚¹ã‚±ãƒ¼ãƒˆ |   159 |\n",
      "| ClosingCeremony    |   145 |\n",
      "| åŒ—äº¬2022           |   101 |\n",
      "| YuzuruHanyu        |   101 |\n",
      "| EXO                |   100 |\n",
      "| ì—‘ì†Œ               |   100 |\n",
      "| åŒ—äº¬äº”è¼ª           |    94 |\n",
      "| åŒ—äº¬ã‚ªãƒªãƒ³ãƒ”ãƒƒã‚¯   |    93 |\n",
      "+--------------------+-------+\n"
     ]
    }
   ],
   "source": [
    "# Extract the screen names which appear among the collection of tweets\n",
    "screen_names = [user_mention['screen_name']\n",
    "               for tweet in results\n",
    "                   for user_mention in tweet['entities']['user_mentions']]\n",
    "\n",
    "# Extract the hashtags which appear among the collection of tweets\n",
    "hashtags = [ hashtag['text']\n",
    "           for tweet in results\n",
    "               for hashtag in tweet['entities']['hashtags']]\n",
    "\n",
    "# Simultaneously determine the frequency of screen names/hashtags, and display the top 10 most common in a table.\n",
    "for label, data in (('Screen Name',screen_names),\n",
    "                   ('Hashtag',hashtags)):\n",
    "    pretty_table = PrettyTable(field_names =[label,'Count'])\n",
    "    counter = Counter(data)\n",
    "    [ pretty_table.add_row(entity) for entity in counter.most_common()[:10]]\n",
    "    pretty_table.align[label] ='l'\n",
    "    pretty_table.align['Count'] = 'r'\n",
    "    print(pretty_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Getting \"All\" Friends and \"All\" Followers of a Popular User in Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Choose a popular twitter user who has many followers in the collected tweets of your case topic.\n",
    "* Get the list of all friends and all followers of the twitter user.\n",
    "* Plot 20 out of the followers, plot their ID numbers, and their screen names in a table.\n",
    "* Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers, and their screen names in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4: Domain Question \n",
    "\n",
    "Run some additional experiments with your data to gain familiarity with the twitter data and twitter API.\n",
    "\n",
    "* Come up with a question, which Twitter data could help answer from your collected tweets, based upon your case topic of your chosen public organization, private company, social community, etc., in a domain.\n",
    "* How could Twitter data help that company/organization/community spend its resources to answer the above question?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nteract": {
   "version": "0.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
